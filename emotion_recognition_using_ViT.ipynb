{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUWLdgbc_h4_",
    "outputId": "26e61d7f-03cd-43be-fa94-0c50f7bf7b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7752eb6c6630>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /packages/54/70/e07c381e6488a77094f04c85c9caf1c8008cdc30778f7019bc52e5285ef0/gdown-5.2.0-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from gdown) (3.15.4)\n",
      "Requirement already satisfied: requests[socks] in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n",
      "Collecting vit-pytorch\n",
      "  Downloading vit_pytorch-1.7.4-py3-none-any.whl.metadata (66 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m446.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting einops>=0.7.0 (from vit-pytorch)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: torch>=1.10 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from vit-pytorch) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from vit-pytorch) (0.19.0)\n",
      "Requirement already satisfied: filelock in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (71.0.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torch>=1.10->vit-pytorch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->vit-pytorch) (12.6.20)\n",
      "Requirement already satisfied: numpy in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torchvision->vit-pytorch) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from torchvision->vit-pytorch) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from jinja2->torch>=1.10->vit-pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from sympy->torch>=1.10->vit-pytorch) (1.3.0)\n",
      "Downloading vit_pytorch-1.7.4-py3-none-any.whl (122 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m949.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m505.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops, vit-pytorch\n",
      "Successfully installed einops-0.8.0 vit-pytorch-1.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!pip install vit-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/adil/anaconda3/envs/fr/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9P9m1Yzm_q64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adil/anaconda3/envs/fr/lib/python3.12/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_K-A78LMsW1c0uOmFNBoGZEHEvrmaZsV\n",
      "To: /media/adil/2 TB/face/1Dataset_Final.rar\n",
      "100%|██████████████████████████████████████| 37.5M/37.5M [00:08<00:00, 4.63MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!gdown --id '1_K-A78LMsW1c0uOmFNBoGZEHEvrmaZsV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Nwl8nghk_q1v",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prompt: unrar my  /content/1Dataset_Final.rar\n",
    "\n",
    "!unrar x /content/1Dataset_Final.rar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "E92UGv-I_qzE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sad', 'angry', 'happy', 'neutral', 'disgust', 'surprise', 'fear']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "dataset_path='./Dataset_Final'\n",
    "classes=os.listdir(dataset_path)\n",
    "# classes.sort()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VyRa0wG6_qwM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "def get_img_df_path(dataset_path, classes):\n",
    "  df=pd.DataFrame(columns=[\"img_paths\",\"classes\"])\n",
    "\n",
    "  i = 0\n",
    "  for c in classes:\n",
    "    image_path=os.path.join(dataset_path,c)\n",
    "    paths = os.listdir(image_path)\n",
    "    for path in paths:\n",
    "      path_to_img=os.path.join(image_path,path)\n",
    "      df.loc[len(df.index)]=[path_to_img,c]\n",
    "\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nY3ZvB2V_qtW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sad' 'angry' 'happy' 'neutral' 'disgust' 'surprise' 'fear']\n",
      "./Dataset_Final/sad/2717.jpg\n",
      "./Dataset_Final/sad/20672.json\n"
     ]
    }
   ],
   "source": [
    "df=get_img_df_path(dataset_path, classes)\n",
    "print(df.classes.unique())\n",
    "print(df['img_paths'][0])\n",
    "print(df['img_paths'][1272])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VZozuw6x_qq5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # for split data into test,train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"img_paths\"],df[\"classes\"], test_size=0.20, random_state=42,stratify=df[\"classes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "veNpnvzb_qoA"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "def move_files(new_p,paths,classes):\n",
    "  if os.path.exists(new_p)==False:\n",
    "    os.mkdir(new_p)\n",
    "\n",
    "  for index,path in enumerate(paths):\n",
    "    new_path=f\"./{new_p}/{classes[index]}/\"\n",
    "    if os.path.exists(new_path)==False:\n",
    "      os.mkdir(new_path)\n",
    "    shutil.move(path,f\"{new_path}\" )\n",
    "\n",
    "move_files(\"train\",X_train.values,y_train.values)\n",
    "move_files(\"test\",X_test.values,y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PhGMK-UEDyLF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "trainset = ImageFolder(root='train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = ImageFolder(root='test', transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f539FnDTDvza"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>TrainingTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Accuracy, Recall, Precision, F1, TrainingTime]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(columns=[\"Name\",\"Accuracy\",\"Recall\",\"Precision\",\"F1\",\"TrainingTime\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "knx5Oo_DDno9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qXVMhRcg_qjB"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tqdm\n",
    "def train_and_evaluate_model(model, name, df, trainloader, testloader, device, epochs, classes):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to train.\n",
    "        name (str): Name of the model or experiment.\n",
    "        df (pd.DataFrame): DataFrame to store metrics.\n",
    "        trainloader (DataLoader): DataLoader for training data.\n",
    "        testloader (DataLoader): DataLoader for testing data.\n",
    "        device (torch.device): Device to run the model on.\n",
    "        epochs (int): Number of training epochs.\n",
    "        classes (list): List of class names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with new metrics.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    model.to(device)\n",
    "\n",
    "    # Training\n",
    "    print(f\"{name} training started.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        num_batches = len(trainloader)\n",
    "\n",
    "        # Progress bar for batches within the epoch\n",
    "        with tqdm.tqdm(total=num_batches, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False) as pbar:\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                pbar.update(1)\n",
    "\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"Testing started.\")\n",
    "    model.eval()\n",
    "    predicteds, all_predictions, actuals = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm.tqdm(testloader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            all_predictions.extend(probabilities.cpu().numpy())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            actuals.extend(labels.cpu().numpy())\n",
    "            predicteds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(actuals, predicteds)\n",
    "    f1 = f1_score(actuals, predicteds, average='macro')\n",
    "    recall = recall_score(actuals, predicteds, average='macro')\n",
    "    precision = precision_score(actuals, predicteds, average='macro')\n",
    "\n",
    "    df.loc[len(df.index)] = [name, accuracy, recall, precision, f1, end_time - start_time]\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(actuals, predicteds, classes)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plot_roc_curve(actuals, all_predictions, classes)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lPH56y0xIoHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIT training started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 1.8058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Loss: 1.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Loss: 1.7241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Loss: 1.6848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Loss: 1.6421\n",
      "Training completed in 371.52 seconds.\n",
      "Testing started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|                                          | 0/958 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m vit \u001b[38;5;241m=\u001b[39m SimpleViT(\n\u001b[1;32m      6\u001b[0m     image_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m224\u001b[39m,\n\u001b[1;32m      7\u001b[0m     patch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     mlp_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Define your class names (labels) function\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVIT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[19], line 62\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, name, df, trainloader, testloader, device, epochs, classes)\u001b[0m\n\u001b[1;32m     59\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     60\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m---> 62\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     63\u001b[0m all_predictions\u001b[38;5;241m.\u001b[39mextend(probabilities\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     64\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "# here I am importing model\n",
    "from vit_pytorch import SimpleViT\n",
    "\n",
    "epochs=5\n",
    "vit = SimpleViT(\n",
    "    image_size = 224,\n",
    "    patch_size = 32,\n",
    "    num_classes = len(classes),\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048\n",
    ")\n",
    "# Define your class names (labels) function\n",
    "df = train_and_evaluate_model(vit, \"VIT\", df, trainloader, testloader, device, epochs, classes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiV-srsg2Sh7"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
